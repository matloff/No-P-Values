---
title: "No P-Values"
author: Norm Matloff
toc: true
---

[Author bio](heather.cs.ucdavis.edu/matloff.html)

**Why Statistical Hypothesis Testing Is a Bad Idea**

> *Abstract:* From the beginning of statistics, in the early 20th century, 
> Null Hypothesis Significance Testing (NHST) was an ill-conceived idea.
> Unfortunately, its usage has become entrenched, producing misleading
> analysis and wasted opportunities. What are the problems with NHST,
> and what should one do instead?

# NHST Is (Too) Comfortable

* We all grew up with it.

* Clean, simple, orderly -- an OCDer's dream! :-)

* Highly developed mathematical foundation.

# The Core Problem

* We wish to determine whether $H_0$ is true or false.

* But $H_0$ **is never true**.

   * $H_0:$ new drug effectiveness = old drug effectiveness

     Can't be true true after many decimal places.

   * $H_0:$ $\beta_i = 0$ in linear model

     The linear model itself is false -- useful maybe -- but just
     an approximation.

   * $H_0:$ population distribution of human weight $W$ is normal/Gaussian

     Measured $W$ is discrete, not continuous.

     No one has a negative weight, or weights 10,000 kg.

   * $H_0:$ Efficient Market Hypothesis

     * Example in pro-NHST essay by
       [Imbens](https://www.aeaweb.org/articles?id=10.1257/jep.35.3.157).
     
     * The EMH is intended only as a rough description, so of course it
       is false in the exact sense.

# Effect of Measurement Error, Especially Bias

   * Biased sampling designs.

   * "I just want know which medical treatment is better."
     $H_0: \mu_1 \leq \mu2$ vs. $H_{\textrm{alt}}: \mu1 > \mu2$.
     Sampling bias can easily push an effect across that threshold, one
     direction of the other.

   * Bias in physical measurements. No physical measurement is 
     infinitely precise.

   * E.g. physics, $H_0:$ gravity waves do not exist.

      * Yes, the existence is either true or false, but our imperfect
        measurements make $H_0$ false.

      * Research on gravity waves relies on umpteen other unproven
        theories.

# Both an Epistemological and Practical Problem

* OK, $H_0$ is never true. But why is that a problem?

* Philosophical: Unscientific -- and just plain silly -- to test for 
  a trait that we know *a priori* is false.

* The American Statistical Association rightly takes pride in statistics
  as a *science*, [saying](www.amstat.org/about-asa) it "the
  development, application, and dissemination of statistical science,
  and that its members "[promote] sound statistical practice to inform 
  public policy and improve human welfare." 

  But testing a hypothesis that one knows *a priori* is false certainly
  isn't science, nor is it "sound practice." 

* Practical: NHST can be extremely misleading, a grave concern in light
  of the pivotal role statistics plays in crucial human events, such as
  in medical cases or legal proceedings.

# The Easy Part: Statistical vs. Practical Significance

* This is the "easy" part, in the sense that most readers here will
  have learned about this issue in the statistics coursework. In other
  words, it would seem that they don't need convincing.

* Yet they do need to be convinced. While they may distinguish
  between statistical vs. practical significance when analyzing
  treatment effects, many do not understand the importance of this
  distinction in other statistical contexts.

* So, let's look in detail at this "easy" part before delving into 
  deeper issues later in this document.

# Running Example: LSAT Data

* See [the Kaggle entry](https://www.kaggle.com/datasets/danofer/law-school-admissions-bar-passage).

* Here is an overview of the variables:

  ```{r}
  load('data/lsa.RData')
  data(lsa)
  names(lsa)
  ```

* The two
[The 'age' variable is apparently birth year, with e.g. 67 meaning
1967.]{.column-margin}
decile scores are class standing in the first and third years of law
school, and 'cluster' refers to the reputed quality of the law school.

* Two variables of particular interest might be the student's score on the
Law School Admission Test (LSAT) and a logical variable indicating
whether the person passed the bar examination.

## Wealth bias in the LSAT?

* There is concern that the LSAT and other similar tests may be
  heavily influenced by family income, thus unfair, especially to
  underrepresented minorities.  

* Let's consider the estimated coefficients in a linear model for the
  LSAT:

  ```{r}
  w <- lm(lsat ~ .,lsa)  # predict lsat from all other variables
  summary(w)
  ```

* There are definitely some salient racial aspects here, but, staying
  with the income issue, look at the coefficient for family income,
  0.3009.

* The p-value is essentially 0, which in an academic research journal
  would classically be heralded with much fanfare, termed "very highly
  significant," with a 3-star insignia.  

* But actually, the impact of family income is not significant in
  practical terms.  Here's why:

* Family income in this dataset is measured in quintiles.  So,
  [Mathematically, testing for a 0 effect is equivalent to checking
  whether the confidence interval contains 0.  But this is missing the
  point of the CI, as we will discuss shortly.]{.column-margin} this
  estimated coefficient says that, for example, if we compare people who
  grew up in the bottom 20% of income with those who were raised in the
  next 20%, the mean LSAT score rises by only about 1/3 of 1 point on a
  5-point scale.  The 95% confidence interval (CI), (0.2304,0.3714),
  again indicates that the effect size here is very small.

* So family income is not an important factor after all, and the
  significance test was highly misleading. The result was statistically
  significant but not practically significant. How did this discrepancy
  arise?

* The above analysis tests the hypothesis

  $$
  H_0: \beta_{\textrm{faminc}} = 0
  $$
  
  using the test statistic using the standard error 
  
  $$
  T = \frac{\widehat{\beta}_{\textrm{faminc}}}
  {\textrm{s.e.}(\widehat{\beta}_{\textrm{faminc}})}
  $$

* As the sample size increases the denominator of $T$ goes to 0.  The
  numerator goes to the population parameter $\beta_{\textrm{faminc}}$
  -- **which is nonzero since all $H_0$s are false**.

* $T$ goes to $\pm \infty$, and thus the p-value goes to 0. In other
  words:

  > Given a large enough dataset, *any* $H_0$ will have a small p-value
  > and will be rejected. **The term "significant" means nothing.**

* The level of "large enough" depends on other factors, e.g. variability
  in the dataset, complexity of the model and so on, but the same
  principle holds.

# Making a Decision, I

* One of the biggest myths about critics of NHST is that they fail to
  realize that the analyst must make a decision. Of course one must make
  a decision -- but based on relevant information, not on an NHST.

* For instance: 

  > In the above analysis, the proper decision is to conclude that family
  > income has rather little effect on LSAT scores, especially compared to
  > several other factors.

* As noted at the outset of this document, making decisions in this
  manner is much less psychologically satisfying than doing an NHST.
  Rather than being automatically in an NHST, the analyst must supply
  his/her own power, devising a criterion for making a decision. 

* But it is the scientifically valid approach, rather
  than relying on "superstition" with NHST.

# Not-So-Easy Parts

* As noted, today's statistically-trained analysts know to watch for
  the phenomenon of statistical significance without practical
  significance -- **in the context of measuring a treatment effect**,
  in the above case, effect of family income. 

* But for many of them, this notion may not be extended to non-treatment
  contexts.

* E.g. "I just want to use NHST to check whether my model fits the data."

## Example: interaction effects in LSAT data

* Say we are considering adding an interaction term between race and
  undergraduate GPA to our above model.   Let's fit this more elaborate
  model, then compare.

  ```{r}
  w1 <- lm(lsat ~ .+race1:ugpa,lsa)  # add interaction
  summary(w1)
  ```

* The Black and white interaction terms with undergraduate GPA are "very
  highly significant."  But that does mean we should use the more
  complex model?

* Let's check the actual impact of including the
  interaction terms on the value of $\widehat{E}(Y|X=t)$, 
  the estimated value of the true regression function
  at some point $t$ chosen to be "typical."

* We will find $\widehat{E}(Y|X=t)$ under both models and compare:
  
  ```{r}
  typx <- lsa[1,-5]  # set up an example case
  predict(w,typx)  # no-interaction model
  predict(w1,typx)  # with-interaction model
  ```

* Adding the interaction term changed the estimated value of the
  regession function--by only about 0.02 out of a 40.23 baseline.  

* So, while the test has strongly indicated a with-interaction model, we
  may well prefer the simpler, no-interaction version. 

# Making a Decision, II

* Again, the above decision on whether to include interaction terms is
  not as psychologically satisfying as the NHST approach. We had to
  supply our own power, devising an *ad hoc* way to help us make a decision. 

* Indeed, this one requires even more "power" on our part, because we
  need to take into account our goal. If we want to do prediction, we
  probably should omit the interaction terms, but if our goal is
  understanding the dynamics of the LSAT, we may want to keep those
  terms.
T
* But this is the rational, scientific approach, rather than relying on
  a test of a hypothesis that we know *a priori* is false, which is
  absurdly unscientific.

# Regarding Confidence Intervals

* Never base judgment on whether "the CI contains 0." That is simply
  backdoor NHST.

* Instead, use the CI as intended:

  a. Its center tells us our point estimate of the population quantity
     of interest.

  b. Its radius gives us an idea of how accurate the point estimate is.

* Item (b) here is actually familiar to the general, nonstatistical
  public, in the from of the *margin of error* in opinion polls. 

* If you were a candidate running for office, wouldn't you want to know
  (b), not just (a)?

* CIs should play a key role in non-NHST analyses.

# Formal Non-NHST Tools 

* Defenders of NHST emphasize that NHST formally addresses uncertainty.

* So for instance it would be desirable to formalize 
  our assessment of adding interaction terms in the
  LSAT model above.

* Following are some examples of how this can be done.

   * To 

# Conclusions

In the classic novel *Don Quixote*, the deranged but well-meaning hero
attacks windmills, which he believes to be evil giants.  American
humorist Mark Twain [viewed the work](en.wikipedia.org/wiki/Don_Quixote)
as having "swept the world's admiration for the mediaeval
chivalry-silliness out of existence." The NHST silliness is no less
deserving of demise.

Statistics textbooks and curricula should finally be purged of the
absurdity of testing hypotheses that we know *a priori* to be false.
Mathematical statisticians should develop new formal non-NHST tools. And
most of all, the ASA should play a leading role in all this.

# Acknowledgements

I was first introduced to this vital issue long ago in graduate
[Prof. Dunn is often credited as the first to use the Bonferroni
Inequality for multiple comparisons]{.column-margin}
school by the late Professor Olive Jean Dunn of the UCLA Biostatistics
Department. I was doing my dissertation in the Mathematics Department.
but took classes in Biostat. Jean brought up the topic casually one day
in lecture, changing my views forever.

