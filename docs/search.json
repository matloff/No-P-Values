[
  {
    "objectID": "NPV.html",
    "href": "NPV.html",
    "title": "No P-Values",
    "section": "",
    "text": "Author bio"
  },
  {
    "objectID": "NPV.html#wealth-bias-in-the-lsat",
    "href": "NPV.html#wealth-bias-in-the-lsat",
    "title": "No P-Values",
    "section": "Wealth bias in the LSAT?",
    "text": "Wealth bias in the LSAT?\n\nThere is concern that the LSAT and other similar tests may be heavily influenced by family income, thus unfair.\nLet’s consider the estimated coefficients in a linear model for the LSAT:\n\nw &lt;- lm(lsat ~ .,lsa)  # predict lsat from all other variables\nsummary(w)\n\n\nCall:\nlm(formula = lsat ~ ., data = lsa)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.290  -2.829   0.120   2.888  16.556 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 31.985789   0.448435  71.328  &lt; 2e-16 ***\nage          0.020825   0.005842   3.565 0.000365 ***\ndecile1      0.127548   0.020947   6.089 1.15e-09 ***\ndecile3      0.214950   0.020919  10.275  &lt; 2e-16 ***\nfam_inc      0.300858   0.035953   8.368  &lt; 2e-16 ***\nugpa        -0.278173   0.080431  -3.459 0.000544 ***\ngendermale   0.513774   0.060037   8.558  &lt; 2e-16 ***\nrace1black  -4.748263   0.198088 -23.970  &lt; 2e-16 ***\nrace1hisp   -2.001460   0.203504  -9.835  &lt; 2e-16 ***\nrace1other  -0.868031   0.262529  -3.306 0.000947 ***\nrace1white   1.247088   0.154627   8.065 7.71e-16 ***\ncluster2    -5.106684   0.119798 -42.627  &lt; 2e-16 ***\ncluster3    -2.436137   0.074744 -32.593  &lt; 2e-16 ***\ncluster4     1.210946   0.088478  13.686  &lt; 2e-16 ***\ncluster5     3.794275   0.124477  30.482  &lt; 2e-16 ***\ncluster6    -5.532161   0.210751 -26.250  &lt; 2e-16 ***\nfulltime2   -1.388821   0.116213 -11.951  &lt; 2e-16 ***\nbarTRUE      1.749733   0.102819  17.018  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.197 on 20782 degrees of freedom\nMultiple R-squared:  0.3934,  Adjusted R-squared:  0.3929 \nF-statistic: 792.9 on 17 and 20782 DF,  p-value: &lt; 2.2e-16\n\n\nThere are definitely some salient racial aspects here, but, staying with the income issue, look at the coefficient for family income, 0.3009.\nThe p-value is essentially 0, which in an academic research journal would be heralded with much fanfare, termed “very highly significant,” with a 3-star insignia.\nBut actually, the impact of family income is not significant in practical terms. Here’s why:\nFamily income in this dataset is measured in quintiles. So, this estimated coefficient says that, for example, if we compare people who grew up in the bottom 20% of income with those who were raised in the next 20%, the mean LSAT score rises by only about 1/3 of 1 point – on a test where scores are typically in the 20s, 30s and 40s. The 95% confidence interval (CI), (0.2304,0.3714), again indicates that the effect size here is very small.\nSo family income is not an important factor after all, and the significance test was highly misleading. The result was statistically significant but not practically significant. How did this discrepancy arise?\nThe above analysis tests the hypothesis\n\\[\nH_0: \\beta_{\\textrm{faminc}} = 0\n\\]\nusing the test statistic based on the standard error,\n\\[\nT = \\frac{\\widehat{\\beta}_{\\textrm{faminc}}}\n{\\textrm{s.e.}(\\widehat{\\beta}_{\\textrm{faminc}})}\n\\]\nAs the sample size increases the denominator of \\(T\\) goes to 0. The numerator goes to the population parameter \\(\\beta_{\\textrm{faminc}}\\) – which is nonzero since all \\(H_0\\)s are false.\n\\(T\\) goes to \\(\\pm \\infty\\), and thus the p-value goes to 0. In other words:\n\nGiven a large enough dataset, any \\(H_0\\) will have a small p-value and will be rejected. The term “significant” means nothing.\n\nThe level of “large enough” depends on other factors, e.g. variability in the dataset, complexity of the model and so on, but the same principle holds."
  },
  {
    "objectID": "NPV.html#example-interaction-effects-in-lsat-data",
    "href": "NPV.html#example-interaction-effects-in-lsat-data",
    "title": "No P-Values",
    "section": "Example: interaction effects in LSAT data",
    "text": "Example: interaction effects in LSAT data\n\nSay we are considering adding an interaction term between race and undergraduate GPA to our above model. Let’s fit this more elaborate model, then compare.\n\nw1 &lt;- lm(lsat ~ .+race1:ugpa,lsa)  # add interactions\nsummary(w1)\n\n\nCall:\nlm(formula = lsat ~ . + race1:ugpa, data = lsa)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-19.1783  -2.8065   0.1219   2.8879  16.0633 \n\nCoefficients:\n                 Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     26.574993   1.219611  21.790  &lt; 2e-16 ***\nage              0.020612   0.005837   3.531 0.000415 ***\ndecile1          0.127585   0.020926   6.097 1.10e-09 ***\ndecile3          0.213918   0.020902  10.234  &lt; 2e-16 ***\nfam_inc          0.295042   0.035939   8.210 2.35e-16 ***\nugpa             1.417659   0.363389   3.901 9.60e-05 ***\ngendermale       0.513686   0.059986   8.563  &lt; 2e-16 ***\nrace1black       4.121631   1.439354   2.864 0.004194 ** \nrace1hisp        1.378504   1.570833   0.878 0.380191    \nrace1other       2.212299   1.976702   1.119 0.263073    \nrace1white       6.838251   1.201559   5.691 1.28e-08 ***\ncluster2        -5.105703   0.119879 -42.590  &lt; 2e-16 ***\ncluster3        -2.427800   0.074862 -32.430  &lt; 2e-16 ***\ncluster4         1.208794   0.088453  13.666  &lt; 2e-16 ***\ncluster5         3.777611   0.124422  30.361  &lt; 2e-16 ***\ncluster6        -5.565130   0.210945 -26.382  &lt; 2e-16 ***\nfulltime2       -1.406151   0.116132 -12.108  &lt; 2e-16 ***\nbarTRUE          1.743800   0.102855  16.954  &lt; 2e-16 ***\nugpa:race1black -2.876555   0.460281  -6.250 4.20e-10 ***\nugpa:race1hisp  -1.022786   0.494210  -2.070 0.038508 *  \nugpa:race1other -0.941852   0.617940  -1.524 0.127479    \nugpa:race1white -1.737553   0.370283  -4.693 2.72e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.193 on 20778 degrees of freedom\nMultiple R-squared:  0.3948,  Adjusted R-squared:  0.3942 \nF-statistic: 645.4 on 21 and 20778 DF,  p-value: &lt; 2.2e-16\n\n\nThe Black and white interaction terms with undergraduate GPA are “very highly significant.” But that does mean we should use the more complex model?\nLet’s check the actual impact of including the interaction terms on the value of \\(\\widehat{E}(Y|X=t)\\), the estimated value of the true regression function at some point \\(t\\) chosen to be “typical.”\nWe will find \\(\\widehat{E}(Y|X=t)\\) under both models and compare:\n\ntypx &lt;- lsa[1,-5]  # set up an example case\npredict(w,typx)  # no-interaction model\n\n      2 \n40.2294 \n\npredict(w1,typx)  # with-interaction model\n\n      2 \n40.2056 \n\n\nAdding the interaction term changed the estimated value of the regession function by only about 0.02 out of a 40.23 baseline.\nSo, while the test has strongly indicated a with-interaction model, we may well prefer the simpler, no-interaction version."
  },
  {
    "objectID": "NPV.html#hierarchical-models",
    "href": "NPV.html#hierarchical-models",
    "title": "No P-Values",
    "section": "Hierarchical models",
    "text": "Hierarchical models\n\nIn the interaction terms example, we informally compared the change in \\(\\widehat{E}(Y|X=t)\\) that occurred when we added interaction terms. How can we formalize this into a CI?\nA CI for the contribution of an interaction term to an overall estimate of \\(E(Y|X=t)\\) is straightforward. The interaction term for GPA and being Black is given in the output, and we can add and subtract 1.96 times the standard error to obtain a CI for a 1-point increase in GPA for Black students, for example.\nA CI for the proportional contribution to \\(E(Y|X=t)\\) can be obtained via the Delta Method, or by the bootstrap.\nThe log-linear model can be used to explore relationships among categorical variables. For instance, this might be used in the LSAT data to analyze relationships between race, gender, family income and so on.\nAgain there is a hierarchy of interaction terms, as in our linear model example, so again either the Delta Method or the bootstrap can be used. The necessary standard errors for DM can be obtained via the “Poisson trick”.\n\n\n\n\nFor the Delta Method, see All of Statistics, by Larry Wasserman. Various R implementations exist, including those not requiring user-specified derivatives.\n\nFor log-linear models, see An Introduction to Categorical Data Analysis, by Alan Agresti. Many R implementations."
  },
  {
    "objectID": "NPV.html#goodness-of-fit-procedures",
    "href": "NPV.html#goodness-of-fit-procedures",
    "title": "No P-Values",
    "section": "Goodness-of-fit procedures",
    "text": "Goodness-of-fit procedures\n\nAs noted earlier, goodness-of-fit tests can be especially problematic in terms of the inappropriate nature of NHST. What can be done instead?\nFirst, ask if assessment of the model is needed in the first place. For instance, many statistical methods, such as the linear model, are robust to normality assumptions, and thus assessing normality is superfluous.\nExplicitly recognize that one’s model is an approximation, by estimating some measure of distance from the population version of one’s model to the true population probabilities, density or whatever.\n\nAs the sample size grows, a fitted linear regression model will converge to the linear function that best approximates the true population regression function.\nA genetic model may be technically false but still serve as a good approximation. As the sample size grows, the fitted probabilities will converge to the set of model probabilities closest to the true population values.\nIn a Markov chain analysis, we might model the holding times as exponentially distributed as an approximation. The resulting estimated exponential distributions will converge to the closest exponential distributions to the true population distributions.\n\nIn all these situations, estimating a distance can help us determine if our (imperfect) model is good enough.\nHow can this idea be implemented?\nThe familiar Kolmogorov-Smirnov procedure is a simple example, allowing use to form a CI for the distance between a model population CDF and the true population CDF.\nThere is an extensive literature on, and R implementations of, minimum distance estimators. However, their computation of standard errors may assume that the given model holds, an assumption that is unacceptable in our context here. Instead, use the methods but compute standard errors using the bootstrap. (The theory on these methods needs to be reworked.)"
  }
]